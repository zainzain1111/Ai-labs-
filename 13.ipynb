{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# Task 1 & 2: Fixed Environment & Data Loading\n",
        "# ==========================================\n",
        "!pip install -q gensim nltk plotly pandas scikit-learn\n",
        "\n",
        "import os\n",
        "import gensim\n",
        "import nltk\n",
        "from nltk import sent_tokenize\n",
        "from gensim.utils import simple_preprocess\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# 1. Clear old data and download fresh\n",
        "!rm -rf data NLP-Dataset\n",
        "!mkdir data\n",
        "!git clone https://github.com/huseinzol05/NLP-Dataset.git\n",
        "\n",
        "# 2. Move files and VERIFY they exist\n",
        "!cp NLP-Dataset/text-corpus/game-of-thrones/*.txt data/\n",
        "\n",
        "# Check if files are actually there\n",
        "files = [f for f in os.listdir('data') if f.endswith('.txt')]\n",
        "print(f\"Files found in data folder: {files}\")\n",
        "\n",
        "if len(files) == 0:\n",
        "    print(\"❌ ERROR: No text files found! Check the download link.\")\n",
        "else:\n",
        "    story = []\n",
        "    for filename in files:\n",
        "        file_path = os.path.join('data', filename)\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            corpus = f.read()\n",
        "            # Split into sentences\n",
        "            sentences = sent_tokenize(corpus)\n",
        "            for sent in sentences:\n",
        "                # Preprocess (lowercase, remove punctuation, etc.)\n",
        "                tokenized = simple_preprocess(sent)\n",
        "                if tokenized: # Only add if the sentence isn't empty\n",
        "                    story.append(tokenized)\n",
        "\n",
        "    print(f\"✅ Success! Total processed sentences: {len(story)}\")\n",
        "    print(f\"Sample sentence format: {story[0]}\")"
      ],
      "metadata": {
        "id": "XKmidfhPxDIL",
        "outputId": "0e375915-c0ec-41f6-9acb-97ec2ddcab2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NLP-Dataset'...\n",
            "remote: Enumerating objects: 11635, done.\u001b[K\n",
            "remote: Counting objects: 100% (903/903), done.\u001b[K\n",
            "remote: Compressing objects: 100% (137/137), done.\u001b[K\n",
            "remote: Total 11635 (delta 803), reused 766 (delta 766), pack-reused 10732 (from 3)\u001b[K\n",
            "Receiving objects: 100% (11635/11635), 1.39 GiB | 23.31 MiB/s, done.\n",
            "Resolving deltas: 100% (5804/5804), done.\n",
            "Updating files: 100% (4073/4073), done.\n",
            "cp: cannot stat 'NLP-Dataset/text-corpus/game-of-thrones/*.txt': No such file or directory\n",
            "Files found in data folder: []\n",
            "❌ ERROR: No text files found! Check the download link.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colab",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}